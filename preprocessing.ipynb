{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import swifter\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from scipy import stats\n",
    "import nltk\n",
    "\n",
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "data = pd.read_csv(\"./all_data.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "text     0\n",
       "type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the new dataset which we will be working with\n",
    "df2 = data.loc[:,['title','text','type']]\n",
    "\n",
    "# Any null values\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/users/s/sarthak_7034/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/users/s/sarthak_7034/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(doc):\n",
    "    \n",
    "    # remove punctuation\n",
    "    doc = re.sub(r\"[\\s+\\.\\!\\/_,|%^*#(+\\\"\\')?<>:-]\", \" \", doc)\n",
    "    \n",
    "    # remove @\n",
    "    pattern2 = r\"@\\S+\"\n",
    "    doc = re.sub(pattern2, \"\", doc)\n",
    "\n",
    "    # tokenization\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    \n",
    "    # lower words\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # remove stopwords\n",
    "    tokens = [w for w in tokens if not w in stop_words] \n",
    "    \n",
    "    # Return a cleaned string or list\n",
    "    return\" \".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf7c52cb04342f1a9a7533c829bdb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d25ec4190b41d1a6f37e2758176359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump u 2019 properties showcase brand ...</td>\n",
       "      <td>stood line trump tower sometimes half hour han...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump foundation tells new york stopped solici...</td>\n",
       "      <td>donald j trump u 2019 foundation informed atto...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald trump prepares white house move tower m...</td>\n",
       "      <td>president elect donald j trump white house out...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>luring chinese investors trump u 2019 name lit...</td>\n",
       "      <td>investment pitch new texas hotel trying lure w...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>melania barron trump u 2019 immediately move w...</td>\n",
       "      <td>president elect donald j trump u 2019 wife mel...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>alabama lawmaker sex couples u 2019 deserve fi...</td>\n",
       "      <td>conservatives oppose marriage equality cite bi...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20011</th>\n",
       "      <td>gop senator david perdue jokes praying obama u...</td>\n",
       "      <td>freshman senator georgia quoted scripture righ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>state department says find emails clinton spec...</td>\n",
       "      <td>state department told republican national comm...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20013</th>\n",
       "      <td>ethiopia obama seeks progress peace security e...</td>\n",
       "      <td>addis ababa ethiopia u 2014 president obama co...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20014</th>\n",
       "      <td>jeb bush suddenly attacking trump matters</td>\n",
       "      <td>jeb bush suddenly attacking trump matters jeb ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20015 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      donald trump u 2019 properties showcase brand ...   \n",
       "1      trump foundation tells new york stopped solici...   \n",
       "2      donald trump prepares white house move tower m...   \n",
       "3      luring chinese investors trump u 2019 name lit...   \n",
       "4      melania barron trump u 2019 immediately move w...   \n",
       "...                                                  ...   \n",
       "20010  alabama lawmaker sex couples u 2019 deserve fi...   \n",
       "20011  gop senator david perdue jokes praying obama u...   \n",
       "20012  state department says find emails clinton spec...   \n",
       "20013  ethiopia obama seeks progress peace security e...   \n",
       "20014          jeb bush suddenly attacking trump matters   \n",
       "\n",
       "                                                    text  type  \n",
       "0      stood line trump tower sometimes half hour han...  real  \n",
       "1      donald j trump u 2019 foundation informed atto...  real  \n",
       "2      president elect donald j trump white house out...  real  \n",
       "3      investment pitch new texas hotel trying lure w...  real  \n",
       "4      president elect donald j trump u 2019 wife mel...  real  \n",
       "...                                                  ...   ...  \n",
       "20010  conservatives oppose marriage equality cite bi...  real  \n",
       "20011  freshman senator georgia quoted scripture righ...  real  \n",
       "20012  state department told republican national comm...  real  \n",
       "20013  addis ababa ethiopia u 2014 president obama co...  real  \n",
       "20014  jeb bush suddenly attacking trump matters jeb ...  real  \n",
       "\n",
       "[20015 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Applying lamdba function to clean text\n",
    "df2['text'] = df2.swifter.apply(lambda row: clean_text(row['text']), axis=1)\n",
    "#Clean title\n",
    "df2['title'] = df2.swifter.apply(lambda row: clean_text(row['title']), axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([df2['title'], df2['text']])\n",
    "MAX_FEATURES = 10000\n",
    "\n",
    "#Assign the type of vectorizer\n",
    "VECTORIZER = 'tfidf'\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def fit_tfidf(documents):\n",
    "    tfidf = TfidfVectorizer(input = 'content', stop_words = 'english',  \n",
    "                            max_features = MAX_FEATURES )\n",
    "    tfidf.fit(documents.values)\n",
    "    return tfidf\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def fit_bow(documents):\n",
    "    bow = CountVectorizer(input='content', stop_words='english',\n",
    "                          max_features = MAX_FEATURES)\n",
    "    bow.fit(documents.values)\n",
    "    return bow\n",
    "\n",
    "if VECTORIZER == 'tfidf':\n",
    "    vectorizer = fit_tfidf(corpus)\n",
    "\n",
    "elif VECTORIZER == 'bow':\n",
    "    vertorizer = fit_bow(corpus)\n",
    "\n",
    "headline_matrix = vectorizer.transform(df2['title'])\n",
    "body_matrix = vectorizer.transform(df2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15011, 20000)\n",
      "(5004, 20000)\n",
      "(15011,)\n",
      "(5004,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "X = hstack([headline_matrix, body_matrix]).toarray()\n",
    "y = df2['type']\n",
    "#Train - test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# #Train - valid\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "#     X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel='linear', random_state= 0)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['real', 'fake', 'fake', ..., 'real', 'real', 'fake'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification report is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.97      0.98      0.98      3013\n",
      "        real       0.97      0.96      0.97      1991\n",
      "\n",
      "    accuracy                           0.97      5004\n",
      "   macro avg       0.97      0.97      0.97      5004\n",
      "weighted avg       0.97      0.97      0.97      5004\n",
      "\n",
      "The accuracy for testing data is 0.9734212629896083\n",
      "The accuracy for training data is 0.9978682299646926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(\"The classification report is:\")\n",
    "print(classification_report(y_test, predict))\n",
    "\n",
    "print(\"The accuracy for testing data is\", np.mean(predict == y_test) )\n",
    "print(\"The accuracy for training data is\", np.mean(classifier.predict(X_train) == y_train) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c0230b97712d87882b3eeba6845e6dc3f3e7571acdedf5897f36f63bc1255a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
